{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f18f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install splink pyspark rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfc7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "from splink.backends.spark import similarity_jar_location\n",
    "from splink import SparkAPI\n",
    "\n",
    "# Path to your custom JAR file\n",
    "CUSTOM_JAR_PATH = r\"C:\\Users\\AbhayPandey\\Desktop\\AP_SS\\Note\\scala-udf-similarity-0.1.1-shaded.jar\"\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"12g\")\n",
    "conf.set(\"spark.default.parallelism\", \"8\")\n",
    "conf.set(\"spark.sql.codegen.wholeStage\", \"false\")\n",
    "conf.set(\"spark.jars\", f\"{similarity_jar_location()},{CUSTOM_JAR_PATH}\")\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.setCheckpointDir(\"./tmp_checkpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184cd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, DoubleType, ArrayType\n",
    "# from pyspark.sql import callUDF\n",
    "\n",
    "\n",
    "# Phonetic / normalization\n",
    "spark.udf.registerJavaFunction(\"accent_remove\", \"uk.gov.moj.dash.linkage.AccentRemover\", StringType())\n",
    "spark.udf.registerJavaFunction(\"double_metaphone\", \"uk.gov.moj.dash.linkage.DoubleMetaphone\", StringType())\n",
    "spark.udf.registerJavaFunction(\"double_metaphone_alt\", \"uk.gov.moj.dash.linkage.DoubleMetaphoneAlt\", StringType())\n",
    "\n",
    "# Similarity\n",
    "spark.udf.registerJavaFunction(\"cosine_distance\", \"uk.gov.moj.dash.linkage.CosineDistance\", DoubleType())\n",
    "spark.udf.registerJavaFunction(\"jaccard_similarity\", \"uk.gov.moj.dash.linkage.JaccardSimilarity\", DoubleType())\n",
    "spark.udf.registerJavaFunction(\"jaro_similarity\", \"uk.gov.moj.dash.linkage.JaroSimilarity\", DoubleType())\n",
    "spark.udf.registerJavaFunction(\"jaro_winkler_similarity\", \"uk.gov.moj.dash.linkage.JaroWinklerSimilarity\", DoubleType())\n",
    "spark.udf.registerJavaFunction(\"lev_damerau_distance\", \"uk.gov.moj.dash.linkage.LevDamerauDistance\", DoubleType())\n",
    "\n",
    "# Tokenisers\n",
    "spark.udf.registerJavaFunction(\"qgram_tokeniser\", \"uk.gov.moj.dash.linkage.QgramTokeniser\", StringType())\n",
    "spark.udf.registerJavaFunction(\"q2gram_tokeniser\", \"uk.gov.moj.dash.linkage.Q2gramTokeniser\", StringType())\n",
    "spark.udf.registerJavaFunction(\"q3gram_tokeniser\", \"uk.gov.moj.dash.linkage.Q3gramTokeniser\", StringType())\n",
    "spark.udf.registerJavaFunction(\"q4gram_tokeniser\", \"uk.gov.moj.dash.linkage.Q4gramTokeniser\", StringType())\n",
    "spark.udf.registerJavaFunction(\"q5gram_tokeniser\", \"uk.gov.moj.dash.linkage.Q5gramTokeniser\", StringType())\n",
    "spark.udf.registerJavaFunction(\"q6gram_tokeniser\", \"uk.gov.moj.dash.linkage.Q6gramTokeniser\", StringType())\n",
    "\n",
    "# Array / explode helpers\n",
    "spark.udf.registerJavaFunction(\"dual_array_explode\", \"uk.gov.moj.dash.linkage.DualArrayExplode\", ArrayType(StringType()))\n",
    "spark.udf.registerJavaFunction(\"latlong_explode\", \"uk.gov.moj.dash.linkage.latlongexplode\", ArrayType(StringType()))\n",
    "\n",
    "# Escaping\n",
    "spark.udf.registerJavaFunction(\"sql_escape\", \"uk.gov.moj.dash.linkage.sqlEscape\", StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.udf.registerJavaFunction(\"accent_remove\", \"uk.gov.moj.dash.linkage.AccentRemover\", \"string\")\n",
    "# spark.udf.registerJavaFunction(\"double_metaphone\", \"uk.gov.moj.dash.linkage.DoubleMetaphone\", \"string\")\n",
    "# spark.udf.registerJavaFunction(\"double_metaphone_alt\", \"uk.gov.moj.dash.linkage.DoubleMetaphoneAlt\", \"string\")\n",
    "# spark.udf.registerJavaFunction(\"cosine_distance\", \"uk.gov.moj.dash.linkage.CosineDistance\", \"double\")\n",
    "# spark.udf.registerJavaFunction(\"jaro\", \"uk.gov.moj.dash.linkage.JaroSimilarity\", \"double\")\n",
    "# spark.udf.registerJavaFunction(\"jaro_winkler\", \"uk.gov.moj.dash.linkage.JaroWinklerSimilarity\", \"double\")\n",
    "# spark.udf.registerJavaFunction(\"jaccard\", \"uk.gov.moj.dash.linkage.JaccardSimilarity\", \"double\")\n",
    "# spark.udf.registerJavaFunction(\"lev_damerau\", \"uk.gov.moj.dash.linkage.LevDamerauDistance\", \"double\")\n",
    "# spark.sql(\"SELECT accent_remove('José'), double_metaphone('Smith'), jaro('martha','marhta')\").show()\n",
    "# #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78170a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+\n",
      "|           full_name|first_and_lastname|first_name|last_name|       dob|birth_place|     zip|gender|occupation|               email|               phone|      address| city|       country|unique_id|\n",
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+\n",
      "|thomas clifford, ...|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|thomaschudleigh24...|          6600795731|devon Streeet|DEVON|United Kingdom|        0|\n",
      "| thomas of chudleigh|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|thomaschudleigh51...|        +01-674-3942|    916 devon|DEVON|United Kingdom|        1|\n",
      "|tom 1st baron cli...|     tom chudleigh|       tom|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|tomchudleigh9081@...|        +01372822399|    022 devon|DEVON|           U.K|        2|\n",
      "|thomas 1st chudleigh|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8hu|  NULL|politician|thomaschudleigh34...|+1-536-360-0037x1027|    261 devon|devon|            UK|        3|\n",
      "|thomas clifford, ...|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  NULL|politician|thomaschudleigh60...|       +449098790850|     17 devon|devon|           U.K|        4|\n",
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"data.csv\"   # replace with your dataset\n",
    "\n",
    "df = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "df = df.withColumn(\"unique_id\", monotonically_increasing_id())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4f95c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roles: {'first_name': 'first_name', 'last_name': 'last_name', 'full_name': 'full_name', 'email': 'email', 'phone': 'phone', 'zip': 'zip', 'city': 'city', 'address': 'address', 'date': 'dob'}\n",
      "Diagnostics: [{'rule': '<splink.internals.blocking_rule_library.ExactMatchRule object at 0x0000011974052190>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}, {'rule': '<splink.internals.blocking_rule_library.ExactMatchRule object at 0x0000011973FD3A90>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}, {'rule': '<splink.internals.blocking_rule_library.And object at 0x00000119740523D0>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}, {'rule': '<splink.internals.blocking_rule_library.And object at 0x0000011974051610>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}, {'rule': '<splink.internals.blocking_rule_library.And object at 0x0000011974053510>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}, {'rule': '<splink.internals.blocking_rule_library.And object at 0x0000011974052FD0>', 'comparisons': 'error', 'kept': False, 'reason': 'count_comparisons_from_blocking_rule() takes 0 positional arguments but 4 were given'}]\n"
     ]
    }
   ],
   "source": [
    "import auto_blocking as ab\n",
    "\n",
    "db_api = SparkAPI(spark_session=spark)\n",
    "\n",
    "settings, roles, diagnostics, df_enhanced, deterministic_rules = ab.auto_generate_settings(df, db_api)\n",
    "\n",
    "\n",
    "print(\"Roles:\", roles)\n",
    "print(\"Diagnostics:\", diagnostics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ae9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  4.21e-09.\n",
      "This means that amongst all possible pairwise record comparisons, one in 237,562,828.25 are expected to match.  With 1,500,396,810 total possible comparisons, we expect a total of around 6.32 matching pairs\n",
      "----- Estimating u probabilities using random sampling -----\n",
      "u probability not trained for email_norm - Exact match on email_norm (comparison vector value: 4). This usually means the comparison level was never observed in the training data.\n",
      "u probability not trained for email_norm - Exact match on username (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name_norm (no m values are trained).\n",
      "    - last_name_norm (no m values are trained).\n",
      "    - city_norm (no m values are trained).\n",
      "    - email_norm (some u values are not trained, no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.`email_norm` = r.`email_norm`\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name_norm\n",
      "    - last_name_norm\n",
      "    - city_norm\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - email_norm\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of first_name_norm >= 0.92 on comparison first_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of first_name_norm >= 0.88 on comparison first_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of first_name_norm >= 0.7 on comparison first_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison first_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of last_name_norm >= 0.92 on comparison last_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of last_name_norm >= 0.88 on comparison last_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro-Winkler distance of last_name_norm >= 0.7 on comparison last_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison last_name_norm not observed in dataset, unable to train m value\n",
      "\n",
      "Iteration 1: Largest change in params was 0.607 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was 0.315 in probability_two_random_records_match\n",
      "Iteration 3: Largest change in params was -0.0984 in the m_probability of city_norm, level `Exact match on city_norm`\n",
      "Iteration 4: Largest change in params was 3.25e-05 in probability_two_random_records_match\n",
      "\n",
      "EM converged after 4 iterations\n",
      "m probability not trained for first_name_norm - Jaro-Winkler distance of first_name_norm >= 0.92 (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for first_name_norm - Jaro-Winkler distance of first_name_norm >= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for first_name_norm - Jaro-Winkler distance of first_name_norm >= 0.7 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for first_name_norm - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for last_name_norm - Jaro-Winkler distance of last_name_norm >= 0.92 (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for last_name_norm - Jaro-Winkler distance of last_name_norm >= 0.88 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for last_name_norm - Jaro-Winkler distance of last_name_norm >= 0.7 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for last_name_norm - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name_norm (some m values are not trained).\n",
      "    - last_name_norm (some m values are not trained).\n",
      "    - email_norm (some u values are not trained, no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "from splink import Linker\n",
    "\n",
    "linker = Linker(df_enhanced, settings, db_api=db_api)\n",
    "\n",
    "# Robust training loop using auto_blocking’s rules\n",
    "try:\n",
    "    linker.training.estimate_probability_two_random_records_match(\n",
    "        deterministic_matching_rules=deterministic_rules,\n",
    "        recall=0.95\n",
    "    )\n",
    "except:\n",
    "    linker.training.estimate_probability_two_random_records_match(\n",
    "        deterministic_matching_rules=deterministic_rules,\n",
    "        recall=1.0\n",
    "    )\n",
    "\n",
    "linker.training.estimate_u_using_random_sampling(max_pairs=5e5)\n",
    "\n",
    "# Train with EM on the first deterministic rule\n",
    "if deterministic_rules:\n",
    "    linker.training.estimate_parameters_using_expectation_maximisation(deterministic_rules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aff4051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blocking time: 0.00 seconds\n",
      "Predict time: 8.95 seconds\n",
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'first_name_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'last_name_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'email_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'email_norm':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "|     match_weight| match_probability|unique_id_l|unique_id_r|first_name_norm_l|first_name_norm_r|gamma_first_name_norm|tf_first_name_norm_l|tf_first_name_norm_r|bf_first_name_norm|bf_tf_adj_first_name_norm|last_name_norm_l|last_name_norm_r|gamma_last_name_norm| tf_last_name_norm_l| tf_last_name_norm_r| bf_last_name_norm|bf_tf_adj_last_name_norm|         city_norm_l|         city_norm_r|gamma_city_norm|      tf_city_norm_l|      tf_city_norm_r|      bf_city_norm|bf_tf_adj_city_norm|        email_norm_l|        email_norm_r|gamma_email_norm|     tf_email_norm_l|     tf_email_norm_r|bf_email_norm|bf_tf_adj_email_norm|\n",
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "|17.75017707610337|0.9999954641122152| 8589941301| 8589941305|          sibella|          sibella|                    4|2.376034945990898E-4|2.376034945990898E-4| 84.31365381100348|       49.917090737479654|           miles|           miles|                   4|3.256409699759026E-4|3.256409699759026E-4|1559.2281553398059|      1.9694787168574608|       wolverhampton|       wolverhampton|              1|0.004446331776284565|0.004446331776284565|118.02598969594173|  1.429162957252845|sibellamiles1748@...|sibellamiles1748@...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|6.360411430001708| 0.987975376271557| 8589936924| 8589936936|              sir|              sir|                    4|0.023065816168003947|0.023065816168003947| 84.31365381100348|       0.5142014101325163|         baronet|         baronet|                   4|0.013351279769012006|0.013351279769012006|1559.2281553398059|    0.048036066264816116|       milton keynes|       milton keynes|              1|0.002997527040191842|0.002997527040191842|118.02598969594173| 2.1199250532583864|sirbaronet7455@ou...|sirbaronet7455@ou...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|7.206995546915258|0.9932772240320209| 8589955776| 8589955787|         frederic|         frederic|                    4|0.001370789391917...|0.001370789391917...| 84.31365381100348|        8.652295727829806|            quin|            quin|                   4|4.993161539630506E-4|4.993161539630506E-4|1559.2281553398059|      1.2844426414287788|              london|                NULL|             -1| 0.05278145529937801|                NULL|               1.0|                1.0|fredericquin9207@...|fredericquin9207@...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|9.932529130819109|0.9989777276731424| 8589959691| 8589959693|             cook|             cook|                    4|1.827719189223767...|1.827719189223767...| 84.31365381100348|        64.89221795872355|            NULL|            NULL|                  -1|                NULL|                NULL|               1.0|                     1.0|north west leices...|north west leices...|              1|4.246496640271775...|4.246496640271775...|118.02598969594173| 14.964176846529787|cook4368@yahoo.co.uk|cook4368@yahoo.co.uk|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = linker.inference.predict(threshold_match_probability=0.9)\n",
    "clusters = results.as_spark_dataframe()\n",
    "\n",
    "clusters.show(10)\n",
    "\n",
    "clusters.write.mode(\"overwrite\").csv(\"splink_predictions.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a66f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blocking time: 0.15 seconds\n",
      "Predict time: 0.48 seconds\n",
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'first_name_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'last_name_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'email_norm':\n",
      "    m values not fully trained\n",
      "Comparison: 'email_norm':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "|     match_weight| match_probability|unique_id_l|unique_id_r|first_name_norm_l|first_name_norm_r|gamma_first_name_norm|tf_first_name_norm_l|tf_first_name_norm_r|bf_first_name_norm|bf_tf_adj_first_name_norm|last_name_norm_l|last_name_norm_r|gamma_last_name_norm| tf_last_name_norm_l| tf_last_name_norm_r| bf_last_name_norm|bf_tf_adj_last_name_norm|         city_norm_l|         city_norm_r|gamma_city_norm|      tf_city_norm_l|      tf_city_norm_r|      bf_city_norm|bf_tf_adj_city_norm|        email_norm_l|        email_norm_r|gamma_email_norm|     tf_email_norm_l|     tf_email_norm_r|bf_email_norm|bf_tf_adj_email_norm|\n",
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "|17.75017707610337|0.9999954641122152| 8589941301| 8589941305|          sibella|          sibella|                    4|2.376034945990898E-4|2.376034945990898E-4| 84.31365381100348|       49.917090737479654|           miles|           miles|                   4|3.256409699759026E-4|3.256409699759026E-4|1559.2281553398059|      1.9694787168574608|       wolverhampton|       wolverhampton|              1|0.004446331776284565|0.004446331776284565|118.02598969594173|  1.429162957252845|sibellamiles1748@...|sibellamiles1748@...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|6.360411430001708| 0.987975376271557| 8589936924| 8589936936|              sir|              sir|                    4|0.023065816168003947|0.023065816168003947| 84.31365381100348|       0.5142014101325163|         baronet|         baronet|                   4|0.013351279769012006|0.013351279769012006|1559.2281553398059|    0.048036066264816116|       milton keynes|       milton keynes|              1|0.002997527040191842|0.002997527040191842|118.02598969594173| 2.1199250532583864|sirbaronet7455@ou...|sirbaronet7455@ou...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|7.206995546915258|0.9932772240320209| 8589955776| 8589955787|         frederic|         frederic|                    4|0.001370789391917...|0.001370789391917...| 84.31365381100348|        8.652295727829806|            quin|            quin|                   4|4.993161539630506E-4|4.993161539630506E-4|1559.2281553398059|      1.2844426414287788|              london|                NULL|             -1| 0.05278145529937801|                NULL|               1.0|                1.0|fredericquin9207@...|fredericquin9207@...|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "|9.932529130819109|0.9989777276731424| 8589959691| 8589959693|             cook|             cook|                    4|1.827719189223767...|1.827719189223767...| 84.31365381100348|        64.89221795872355|            NULL|            NULL|                  -1|                NULL|                NULL|               1.0|                     1.0|north west leices...|north west leices...|              1|4.246496640271775...|4.246496640271775...|118.02598969594173| 14.964176846529787|cook4368@yahoo.co.uk|cook4368@yahoo.co.uk|               4|3.954366609328351E-5|3.954366609328351E-5|       1024.0|    23.4610107421875|\n",
      "+-----------------+------------------+-----------+-----------+-----------------+-----------------+---------------------+--------------------+--------------------+------------------+-------------------------+----------------+----------------+--------------------+--------------------+--------------------+------------------+------------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = linker.inference.predict(threshold_match_probability=0.9).as_spark_dataframe()\n",
    "preds.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad82f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Report saved to report.parquet and report.csv\n",
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+----------+---------------+\n",
      "|           full_name|first_and_lastname|first_name|last_name|       dob|birth_place|     zip|gender|occupation|               email|               phone|      address| city|       country|unique_id|cluster_id|partition_group|\n",
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+----------+---------------+\n",
      "|thomas clifford, ...|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|thomaschudleigh24...|          6600795731|devon Streeet|DEVON|United Kingdom|        0|      NULL|              1|\n",
      "| thomas of chudleigh|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|thomaschudleigh51...|        +01-674-3942|    916 devon|DEVON|United Kingdom|        1|      NULL|              2|\n",
      "|tom 1st baron cli...|     tom chudleigh|       tom|chudleigh|1630-08-01|      devon|tq13 8df|  male|politician|tomchudleigh9081@...|        +01372822399|    022 devon|DEVON|           U.K|        2|      NULL|              3|\n",
      "|thomas 1st chudleigh|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8hu|  NULL|politician|thomaschudleigh34...|+1-536-360-0037x1027|    261 devon|devon|            UK|        3|      NULL|              4|\n",
      "|thomas clifford, ...|  thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|tq13 8df|  NULL|politician|thomaschudleigh60...|       +449098790850|     17 devon|devon|           U.K|        4|      NULL|              5|\n",
      "+--------------------+------------------+----------+---------+----------+-----------+--------+------+----------+--------------------+--------------------+-------------+-----+--------------+---------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def create_cluster_report(df, preds, report_parquet=\"report.parquet\", report_csv=\"report.csv\"):\n",
    "    # --- Step 1: Edges\n",
    "    edges = preds.filter(F.col(\"match_probability\") >= 0.9) \\\n",
    "                 .select(F.col(\"unique_id_l\").alias(\"src\"),\n",
    "                         F.col(\"unique_id_r\").alias(\"dst\"))\n",
    "\n",
    "    # --- Step 2: Components\n",
    "    vertices = edges.select(\"src\").union(edges.select(\"dst\")).distinct() \\\n",
    "                   .withColumnRenamed(\"src\", \"id\") \\\n",
    "                   .withColumn(\"component\", F.col(\"id\"))\n",
    "    components = vertices\n",
    "    changed = True\n",
    "    while changed:\n",
    "        updated = edges.join(components, edges.src == components.id, \"inner\") \\\n",
    "                       .select(edges.dst.alias(\"id\"), components.component) \\\n",
    "                       .union(components.select(\"id\", \"component\")) \\\n",
    "                       .groupBy(\"id\").agg(F.min(\"component\").alias(\"component\"))\n",
    "        changed = updated.join(components, [\"id\"], \"left\") \\\n",
    "                         .filter(updated.component != components.component).count() > 0\n",
    "        components = updated\n",
    "\n",
    "    # --- Step 3: Sequential cluster_id\n",
    "    distinct_clusters = components.select(\"component\").distinct() \\\n",
    "                                  .withColumn(\"cluster_id\",\n",
    "                                              F.row_number().over(Window.orderBy(\"component\")))\n",
    "    components = components.join(distinct_clusters, \"component\", \"left\")\n",
    "\n",
    "    # --- Step 4: Join back with original df\n",
    "    df_with_clusters = df.join(components, df.unique_id == components.id, \"left\") \\\n",
    "                         .drop(\"id\", \"component\")\n",
    "\n",
    "    # --- Step 5: Partition group\n",
    "    window_spec = Window.partitionBy(\"cluster_id\").orderBy(\"unique_id\")\n",
    "    df_with_clusters = df_with_clusters.withColumn(\n",
    "        \"partition_group\", F.row_number().over(window_spec)\n",
    "    )\n",
    "\n",
    "    # --- Step 6: Save\n",
    "    df_with_clusters.write.mode(\"overwrite\").parquet(report_parquet)\n",
    "    df_with_clusters.write.mode(\"overwrite\").option(\"header\", True).csv(report_csv)\n",
    "\n",
    "    print(f\"✅ Report saved to {report_parquet} and {report_csv}\")\n",
    "    return df_with_clusters\n",
    "\n",
    "report_df = create_cluster_report(df, preds, \"report.parquet\", \"report.csv\")\n",
    "report_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcee7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deduped representatives saved to deduped.csv\n",
      "+----------+----------+\n",
      "|cluster_id|    rep_id|\n",
      "+----------+----------+\n",
      "|      NULL|        26|\n",
      "|         1|8589936936|\n",
      "|         3|8589955787|\n",
      "|         4|8589959691|\n",
      "|         2|8589941305|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deduped = report_df.groupBy(\"cluster_id\").agg(F.first(\"unique_id\").alias(\"rep_id\"))\n",
    "deduped.write.mode(\"overwrite\").option(\"header\", True).csv(\"deduped.csv\")\n",
    "\n",
    "print(\"✅ Deduped representatives saved to deduped.csv\")\n",
    "deduped.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0873cca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinkerInference' object has no attribute 'predict_from_dataframes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpotential_duplicate\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m example_record = {\u001b[33m\"\u001b[39m\u001b[33mfirst_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mJohn\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlast_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSmith\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33memail\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjohn@example.com\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcheck_new_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinker\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcheck_new_record\u001b[39m\u001b[34m(new_record, linker, threshold)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_new_record\u001b[39m(new_record: \u001b[38;5;28mdict\u001b[39m, linker, threshold=\u001b[32m0.9\u001b[39m):\n\u001b[32m      4\u001b[39m     single_df = spark.createDataFrame([new_record])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     preds = \u001b[43mlinker\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_from_dataframes\u001b[49m(single_df, threshold_match_probability=threshold)\n\u001b[32m      6\u001b[39m     pdf = preds.as_pandas_dataframe()\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pdf) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'LinkerInference' object has no attribute 'predict_from_dataframes'"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def check_new_record(new_record: dict, linker, threshold=0.9):\n",
    "    single_df = spark.createDataFrame([new_record])\n",
    "    preds = linker.inference.predict_from_dataframes(single_df, threshold_match_probability=threshold)\n",
    "    pdf = preds.as_pandas_dataframe()\n",
    "    if len(pdf) == 0:\n",
    "        return \"unique\"\n",
    "    score = max(pdf[\"match_probability\"])\n",
    "    if score > threshold:\n",
    "        return \"duplicate\"\n",
    "    return \"potential_duplicate\"\n",
    "\n",
    "example_record = {\"first_name\": \"John\", \"last_name\": \"Smith\", \"email\": \"john@example.com\"}\n",
    "print(check_new_record(example_record, linker))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
