{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe392b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "from universal_blocking import normalize_date, normalize_time, BlockingFactory\n",
    "import altair as alt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "conn_str = \"trino://root@3.108.199.0:32092/mysql/ap\"\n",
    "engine = create_engine(conn_str, connect_args={'http_scheme': 'http'})\n",
    "\n",
    "# Load data from the database\n",
    "df_pandas = pd.read_sql(\"SELECT * FROM mysql.ap.people_data LIMIT 1000000\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d540ea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      " shape: (5, 16)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ full_name ┆ first_and ┆ first_nam ┆ surname   ┆ … ┆ city      ┆ country   ┆ postal_co ┆ RecordID │\n",
      "│ ---       ┆ _surname  ┆ e         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ de        ┆ ---      │\n",
      "│ str       ┆ ---       ┆ ---       ┆ str       ┆   ┆ str       ┆ str       ┆ ---       ┆ i64      │\n",
      "│           ┆ str       ┆ str       ┆           ┆   ┆           ┆           ┆ str       ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ a hu e    ┆ a hu e    ┆ a hu      ┆ e         ┆ … ┆ STOCKTON- ┆ Uzbekis a ┆ s190sh    ┆ 1        │\n",
      "│ glefield  ┆ glefield  ┆           ┆ glefield  ┆   ┆ ON-TEES   ┆           ┆           ┆          │\n",
      "│ a         ┆ a         ┆ a         ┆ null      ┆ … ┆ STOCKTON- ┆ Chi a     ┆ s5 7hb    ┆ 2        │\n",
      "│           ┆           ┆           ┆           ┆   ┆ ON-TEES   ┆           ┆           ┆          │\n",
      "│ a ie e    ┆ a ie e    ┆ a ie      ┆ e         ┆ … ┆ STOCKTON- ┆ Rwa da    ┆ s190sh    ┆ 3        │\n",
      "│ glefield  ┆ glefield  ┆           ┆ glefield  ┆   ┆ ON-TEES   ┆           ┆           ┆          │\n",
      "│ a e       ┆ a e       ┆ a         ┆ e         ┆ … ┆ STOCKTON- ┆ B i ish I ┆ s190sh    ┆ 4        │\n",
      "│ glefield  ┆ glefield  ┆           ┆ glefield  ┆   ┆ ON-TEES   ┆ dia Ocea  ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆ Te i o y  ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆ (C…       ┆           ┆          │\n",
      "│ a hu e    ┆ a hu e    ┆ a hu      ┆ e         ┆ … ┆           ┆ I do esia ┆ null      ┆ 5        │\n",
      "│ glefiwld  ┆ glefiwld  ┆           ┆ glefiwld  ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Add a unique RecordID for tracking\n",
    "df_pandas['RecordID'] = range(1, len(df_pandas) + 1)\n",
    "\n",
    "# Clean string columns by removing unwanted characters and stripping whitespace\n",
    "string_cols = df_pandas.select_dtypes(include=['object']).columns\n",
    "df_pandas[string_cols] = df_pandas[string_cols].astype(str).replace(['', 'nan', 'None'], None).apply(lambda x: x.str.strip().str.replace(r'[\\\\n\\\\r\\\\t%]', ' ', regex=True))\n",
    "\n",
    "# Reduce multiple spaces to a single space in all string columns\n",
    "df_pandas[string_cols] = df_pandas[string_cols].apply(lambda x: x.str.replace(r' +', ' ', regex=True))\n",
    "\n",
    "# Normalize date and time columns if they exist\n",
    "if 'dob' in df_pandas:\n",
    "    df_pandas['dob'] = df_pandas['dob'].apply(normalize_date)\n",
    "if 'time' in df_pandas:\n",
    "    df_pandas['time'] = df_pandas['time'].apply(normalize_time)\n",
    "\n",
    "# Convert to Polars DataFrame for high-performance operations\n",
    "df = pl.from_pandas(df_pandas)\n",
    "\n",
    "# Display the first 5 rows of the processed data\n",
    "print(\"Sample:\\n\", df.head(5))\n",
    "\n",
    "# Dispose of the database engine connection\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc16e2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrinoBlocking' object has no attribute 'attr_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Automatically create a blocker with rules based on the data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m blocker = \u001b[43mBlockingFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauto_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmysql.ap.people_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_id_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRecordID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Run all blocking rules in parallel for efficiency\u001b[39;00m\n\u001b[32m      5\u001b[39m per_rule_dfs = blocker.run_all(parallel=\u001b[38;5;28;01mTrue\u001b[39;00m, max_workers=\u001b[32m8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhayPandey\\Desktop\\Passion\\blocking\\universal_blocking.py:519\u001b[39m, in \u001b[36mBlockingFactory.auto_create\u001b[39m\u001b[34m(df, conn_str, view_name, record_id_col)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_create\u001b[39m(df: Optional[pl.DataFrame] = \u001b[38;5;28;01mNone\u001b[39;00m, conn_str: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, view_name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, record_id_col: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mRecordID\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    518\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m conn_str \u001b[38;5;129;01mand\u001b[39;00m view_name:\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHybridBlocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_id_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mProvide Polars DataFrame, conn_str, and view_name\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhayPandey\\Desktop\\Passion\\blocking\\universal_blocking.py:475\u001b[39m, in \u001b[36mHybridBlocking.__init__\u001b[39m\u001b[34m(self, df, conn_str, view_name, record_id_col)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pl.DataFrame, conn_str: \u001b[38;5;28mstr\u001b[39m, view_name: \u001b[38;5;28mstr\u001b[39m, record_id_col: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mRecordID\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28mself\u001b[39m.trino_blocker = \u001b[43mTrinoBlocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_id_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.polars_blocker = PolarsBlocking(df, record_id_col)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m.existing_pairs = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhayPandey\\Desktop\\Passion\\blocking\\universal_blocking.py:93\u001b[39m, in \u001b[36mTrinoBlocking.__init__\u001b[39m\u001b[34m(self, conn_str, view_name, record_id_col)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = create_engine(conn_str, connect_args={\u001b[33m'\u001b[39m\u001b[33mhttp_scheme\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.available_columns = pd.read_sql(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mview_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m LIMIT 0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine).columns\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m.attr_map = \u001b[43m{\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mavailable_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattr_map\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m.existing_pairs = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.rules = \u001b[38;5;28mself\u001b[39m._generate_exact_rules()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhayPandey\\Desktop\\Passion\\blocking\\universal_blocking.py:93\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = create_engine(conn_str, connect_args={\u001b[33m'\u001b[39m\u001b[33mhttp_scheme\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.available_columns = pd.read_sql(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mview_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m LIMIT 0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine).columns\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m.attr_map = {attr: col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.available_columns \u001b[38;5;28;01mif\u001b[39;00m (attr := match_attribute(col)) \u001b[38;5;129;01mand\u001b[39;00m attr \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattr_map\u001b[49m}\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m.existing_pairs = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.rules = \u001b[38;5;28mself\u001b[39m._generate_exact_rules()\n",
      "\u001b[31mAttributeError\u001b[39m: 'TrinoBlocking' object has no attribute 'attr_map'"
     ]
    }
   ],
   "source": [
    "# Automatically create a blocker with rules based on the data\n",
    "blocker = BlockingFactory.auto_create(df=df, conn_str=conn_str, view_name=\"mysql.ap.people_data\", record_id_col=\"RecordID\")\n",
    "\n",
    "# Run all blocking rules in parallel for efficiency\n",
    "per_rule_dfs = blocker.run_all(parallel=True, max_workers=8)\n",
    "\n",
    "# Generate and display a report on the performance of each rule\n",
    "stats_df, chart = blocker.generate_rule_report(per_rule_dfs, save_html_path=\"rule_report.html\")\n",
    "\n",
    "if stats_df is not None:\n",
    "    print(\"Rule Report:\\\\n\", stats_df)\n",
    "    chart.display()\n",
    "else:\n",
    "    print(\"No pairs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pairs from all rules into a single DataFrame\n",
    "merged_pairs = blocker.merge_all()\n",
    "\n",
    "if not merged_pairs.is_empty():\n",
    "    # Save the identified pairs to a CSV file\n",
    "    merged_pairs.write(\"pairs.csv\")\n",
    "\n",
    "    # Count the number of pairs generated by each rule\n",
    "    counts = merged_pairs.group_by(\"RulesUsed\").len().sort(\"len\", descending=True)\n",
    "\n",
    "    # Create a bar chart to visualize the results\n",
    "    chart = alt.Chart(counts.to_pandas()).mark_bar().encode(\n",
    "        x=alt.X(\"RulesUsed:N\", sort=\"-y\", title=\"Blocking Rule\"),\n",
    "        y=alt.Y(\"len:Q\", title=\"Unique Pairs\"),\n",
    "        tooltip=[\"RulesUsed:N\", alt.Tooltip(\"len:Q\", format=\",.0f\", title=\"Pairs\")],\n",
    "        color=alt.Color(\"len:Q\", scale=alt.Scale(scheme=\"blues\"))\n",
    "    ).properties(title=\"Unique Pairs by Rule\", width=600, height=400)\n",
    "\n",
    "    # Save the chart to an HTML file and display it\n",
    "    chart.save(\"pairs_chart.html\")\n",
    "    chart.display()\n",
    "    print(f\"Saved {len(merged_pairs)} pairs to pairs.csv\")\n",
    "else:\n",
    "    print(\"No pairs to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
